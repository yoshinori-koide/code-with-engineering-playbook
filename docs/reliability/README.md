# 信頼性

他のすべてのCSE Eng Fundamentalsは、より信頼性の高いインフラストラクチャに向けて取り組んでいます。自動化された統合とデプロイにより、コードが適切にテストされ、人為的エラーを取り除くことができます。また、リリースが遅いと、コードの信頼性が高まります。可観測性は、エラーが発生して安定した状態に戻るときに、エラーをより迅速に特定するのに役立ちます。

ただし、より信頼性の高いソリューションを確保するために、前のカテゴリにうまく適合しない、実行できる追加の手順がいくつかあります。これらについては、以下で説明します。

## 「Foot-Guns」を削除します

開発チームが自分の足を撃たないようにします。人々は間違いを犯します。生産で行われた間違いはその人のせいではなく、その間違いの発生を防がないのはシステムの集合的なせいです。

これらのフットガンを取り外すための一般的なツールについては、以下のリストを確認してください。

* Kubernetesでは、[Admission Controllers](https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/)を活用して、「悪いこと」が発生しないようにします。
  * Webhookアドミッションコントローラーを使用してカスタムコントローラーを作成できます。
* [Gatekeeper](https://github.com/open-policy-agent/gatekeeper)は、事前に構築されたWebhookアドミッションコントローラーであり、内部で[OPA](https://github.com/open-policy-agent/opa)を活用し、すぐに使用できる[保護をサポート](https://github.com/open-policy-agent/gatekeeper-library/tree/master/library)します。

ユーザーが間違いを犯した場合でも、「誰かがそれを行う可能性があるのはなぜですか」と尋ねないでください。「将来、これが起こらないようにするにはどうすればよいですか」と尋ねてください。

## 自動スケーリング

可能な限り、デプロイメントに自動スケーリングを活用してください。垂直方向の自動スケーリングでは、CPU、ディスク、RAMなどのパラメーターを調整することで、VMをスケーリングできます。一方、水平方向の自動スケーリングでは、展開をサポートする実行中のイメージの数を調整できます。自動スケーリングは、システムがトラフィックの無機的な増加に対応し、リソース不足によるリクエストの失敗を防ぐのに役立ちます。

> 注：K8sのような環境では、水平方向と垂直方向の両方の自動スケーリングがネイティブソリューションとして提供されます。ただし、VMが各ポッドをサポートしている場合は、ポッド数の増加に対応するために自動スケーリングが必要になることもあります。

自動スケーリングに影響を与えるパラメータは調整が難しい場合があることにも注意してください。CPUまたはRAMの使用率、要求率などの一般的なメトリックでは不十分な場合があります。キャッシュ排除率などのカスタムメトリックを検討したい場合があります。

## 負荷制限とDOS保護

多くの場合、サービス拒否(DOS)攻撃は悪意のある攻撃者による行為と見なされるため、システムのゲートに負荷を軽減し、それを1日と呼びます。実際には、多くのDOS攻撃は意図的ではなく、自発的なものです。キャッシュを停止する不適切なデプロイメントは、ダウンストリームサービスに打撃を与えます。分散システムからのポーリングは同期し、[雷の群れ](https://en.wikipedia.org/wiki/Thundering_herd_problem)になります。設定を誤るとエラーが発生し、クライアントが制御不能に再試行します。リクエストは、将来の読み取りでサーバーがクラッシュするほど大きくなるまで、保存されたオブジェクトに追加されます。リストは続きます。

身を守るために次の手順に従ってください。

* ユーザーがトリガーしないフローから発生するアクションにジッター（ランダム）を追加します（つまり、cronのスリープ、またはダウンストリームサービスを継続的にポーリングするジョブにランダムな期間を追加します）。
* クライアントコードに[指数バックオフ再試行ポリシー](https://en.wikipedia.org/wiki/Exponential_backoff)を実装する。
* サーバーに負荷制限を追加します（はい、内部マイクロサービスも）。
  * これは、envoy のようなサイドカーを活用するときに簡単に構成できます。
* ユーザー要求を逆シリアル化するときは注意し、バッファー制限を使用してください。
  * すなわち：HTTP / gRPCサーバーは、ソケットから読み取られるデータの量に制限を設定できます。
* 使用率、サーバーの再起動、またはオフラインになることについてアラートを設定し、システムに障害が発生している可能性があることを検出します。

これらのタイプのエラーは、システムの重要でない部分がサービス全体を停止させるカスケード障害を引き起こす可能性があります。それに応じて計画を立て、障害時にシステムがどのように劣化する可能性があるかを十分に考慮してください。

## バックアップデータ

データが失われたり、破損したり、誤って削除されたりします。それは起こります。データのバックアップを取り、システムをできるだけ早くオンラインに戻すのに役立ててください。これは、コードがデータを削除または破損したり、ストレージレイヤーでボリュームを失ったり、暗号化キーを失ったりして、アプリケーションスタックで発生する可能性があります。

次のようなことを検討してください。

* データの復元にはどのくらい時間がかかりますか。
* どのくらいのデータ損失を許容できますか。
* データの損失があることに気付くのにどのくらい時間がかかりますか。

**スナップショット** と **増分** のバックアップの違いを調べてください。適切なポリシーは、期間Nで増分バックアップを作成し、期間M（N < M）でスナップショットバックアップを作成することです。

## 稼働時間の目標と適切な失敗

システムが100％の稼働時間をターゲットにできないことは既知の事実です。今日のソフトウェアシステムには、これを達成するにはあまりにも多くの要因があり、その多くは私たちの制御の及ばないものです。更新されることはなく、100％バグがないサービスでも失敗します。アップストリームDNSサーバーには常に問題があります。ハードウェアが壊れています。停電、バックアップ発電機の故障。世界は混沌としている。優れたサービスは、稼働時間の「9」の数を対象としています。つまり、99.99％の稼働率は、システムの「予算」が毎月4分22秒であることを意味します。一部の月は100％の稼働時間を達成する可能性があります。これは、予算が翌月に繰り越されることを意味します。稼働時間の意味は、すべての人にとって、そして定義するサービスによって異なります。

期間の終わり（つまり、年、四半期）に残った予算を使用して、そのサービスを意図的に停止し、残りのシステムが期待どおりに機能しなくなるようにすることをお勧めします。多くの場合、他のエンジニアやサービスは、その追加の達成された可用性に依存するようになり、システムが正常に失敗することを保証することは健全である可能性があります。

障害を予測することで、ソフトウェアスタックに正常な障害（または正常な劣化）を組み込むことができます。いくつかの戦術は次のとおりです。

* 健全なサービスへのフェイルオーバー
  * [リーダーの選出](https://en.wikipedia.org/wiki/Leader_election)は、リーダーが問題を経験した場合に備えて、健全なサービスを待機状態に保つために使用できます。
  * クラスタ全体のフェールオーバーにより、トラフィックを別のリージョンまたはアベイラビリティーゾーンにリダイレクトできます。
  * **依存サービス** のダウンストリーム障害をヘルスチェックを介してスタックに伝播し、入力ポイントが正常なサービスに再ルーティングできるようにします。
* [ブレーカー回路](https://techblog.constantcontact.com/software-development/circuit-breakers-and-microservices/#:~:text=The%20Circuit%20breaker%20pattern%20helps,unavailable%20or%20have%20high%20latency.)は、システム全体にエラーを伝播するのではなく、要求に応じて早期に救済することができます

## 練習

[上記の推奨事項は、テストされていない場合は機能しません](https://thinkmeta.net/2010/11/06/what-is-an-untested-dr-plan-worth/)。マウント方法がわからない場合、バックアップは無意味です。クラスターのフェイルオーバーおよびその他の緩和策は、テストされていない場合、時間の経過とともに低下します。上記をテストするためのヒントを次に示します。

### プレイブックを維持する

なじみのない領域を開発者がナビゲートするためのプレイブックがなければ、ソフトウェアサービスは完成しません。プレイブックは徹底的であり、すべての既知の障害シナリオと軽減策を網羅している必要があります。

### メンテナンス演習を実行する

時間をかけてシナリオを作成し、D＆Dスタイルのキャンペーンを実行して問題を解決してください。これは、新しい環境を起動してエラーを挿入するのと同じくらい複雑な場合もあれば、「プレーヤー」にダッシュボードに移動して、作成されたシナリオで表示される内容を説明するのと同じくらい簡単な場合もあります（少し想像力が必要です）。プレイブックは、ユーザーを正しい解決策/緩和策に **簡単** にナビゲートする必要があります。そうでない場合は、プレイブックを更新してください。

### カオステスト

自動化されたカオステストを活用して、状況がどのように機能するかを確認します。次のツールのリストを確認してください。

* [Chaos Monkey](https://netflix.github.io/chaosmonkey/)
* [Kraken](https://github.com/cloud-bulldozer/kraken)
* [Linkerd](https://linkerd.io/2/features/fault-injection/)のような多くのサービスメッシュは、サイドカーを使用してフォールトインジェクションツールを提供します。
* [Chaos Mesh](https://github.com/chaos-mesh/chaos-mesh)

## すべての失敗を分析する

[事後分析](https://en.wikipedia.org/wiki/Postmortem_documentation)を作成することは、根本的な原因と失敗のアクションアイテムを文書化するための優れた方法です。また、繰り返し発生する問題を追跡し、修正に優先順位を付けるための強力なケースを作成するための優れた方法でもあります。

これは、通常のアジャイル[再検討](../agile-development/retrospectives.md)に結び付けることもできます。
